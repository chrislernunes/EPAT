{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_Risk.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XGJCXu_c1vm",
        "colab_type": "code",
        "outputId": "962380ca-e2dd-4297-e2e3-6d76abdacc6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!pip install yfinance\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.init as init"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.6/dist-packages (0.1.50)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.6/dist-packages (from yfinance) (2.21.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from yfinance) (0.0.9)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from yfinance) (1.17.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.6/dist-packages (from yfinance) (0.25.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (2019.9.11)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->yfinance) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.24->yfinance) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTZVkvF9Z2kM",
        "colab_type": "code",
        "outputId": "46ebde20-e1e3-44bf-e49e-5bb4feab1d55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "price = yf.download(\"AAPL\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqkAaINJvw0i",
        "colab_type": "code",
        "outputId": "963a793a-0ad4-4dc6-cc04-6262ebc4a14b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "price['Adj Close'].plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7feb4787e0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAyVe+kMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3TaZhsnVp6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MTimeSLoader():\n",
        "    def __init__(self, price,batch_size,seq_len):\n",
        "        self.price = price\n",
        "        self.batch_size = batch_size\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def RSICalc(self,price):\n",
        "        delta = price['Adj Close'].diff()\n",
        "        dUp, dDown = delta.copy(), delta.copy()\n",
        "        dUp[dUp < 0] = 0\n",
        "        dDown[dDown > 0] = 0\n",
        "        RolUp = dUp.rolling(window=14).mean()\n",
        "        RolDown = dDown.abs().rolling(window=14).mean()\n",
        "        return np.where(RolDown != 0,RolUp / RolDown,1)\n",
        "\n",
        "    def getTI(self,price):\n",
        "        adjustment = price['Adj Close']/price['Close']\n",
        "\n",
        "        # VOLITILIY\n",
        "        # Bollinger Bands\n",
        "        std_20 = price['Adj Close'].rolling(window=20).std() \n",
        "        ub = price['Adj Close'] - 2 * std_20\n",
        "        lb = price['Adj Close'] + 2 * std_20\n",
        "\n",
        "        # TREND\n",
        "        # Moving Averages\n",
        "        ma_10 = price['Adj Close'].rolling(window=10).mean()\n",
        "        ma_20 = price['Adj Close'].rolling(window=20).mean()\n",
        "\n",
        "        # Moving Averae Convergence Divergence\n",
        "        ema_26 = pd.Series.ewm(price['Adj Close'],span=26).mean()\n",
        "        ema_12 = pd.Series.ewm(price['Adj Close'],span=12).mean()\n",
        "        macd = ema_26-ema_12\n",
        "\n",
        "        # MOMENTUM \n",
        "        # RSI \n",
        "        rsi = self.RSICalc(price)\n",
        "        return pd.DataFrame({'ma_10':ma_10,'ma_20':ma_20,'macd':macd,'bol_lb':lb,'bol_up':ub, 'rsi':rsi})\n",
        "\n",
        "    def getFI(self,price):\n",
        "        return pd.DataFrame({})\n",
        "\n",
        "    def getFFTComponents(self,price):\n",
        "        close_fft = np.fft.fft(np.asarray(price['Adj Close'].tolist()))\n",
        "        fft_df = pd.DataFrame({'fft':close_fft})\n",
        "        real = fft_df['fft'].apply(lambda x: np.abs(x))\n",
        "        angle = fft_df['fft'].apply(lambda x: np.angle(x))\n",
        "        df =  pd.DataFrame(data = {'real':real,'angle':angle})\n",
        "        df.index = price.index\n",
        "        return df\n",
        "\n",
        "    def getFeatures(self,price):\n",
        "        return pd.concat([price['Adj Close'].pct_change(),]) # self.getTI(price), self.getFI(price), self.getFFTComponents(price)],axis=1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.prices.shape[0])\n",
        "\n",
        "    def get(self):\n",
        "        data = self.getFeatures(self.price)[30:]\n",
        "        filt = data.to_numpy()[self.seq_len:]\n",
        "        items = filt.shape[0]\n",
        "        choice = np.random.choice(items, self.batch_size, replace=False)\n",
        "        return np.vstack([np.vstack([filt[r] for r in range(i-self.seq_len,i)]).reshape(self.seq_len,-1) for i in choice]).reshape(self.batch_size,self.seq_len,-1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny6VOomcyrBQ",
        "colab_type": "code",
        "outputId": "bdaebb0e-3399-408a-84b1-0d393bd47f94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batch_size = 32\n",
        "window_size = 12\n",
        "MTimeSLoader(price,batch_size,window_size).get().shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 12, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cz3K_ly9cjlI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weight_init(m):\n",
        "    if isinstance(m, nn.Conv1d):\n",
        "        init.normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.Conv2d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.Conv3d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.ConvTranspose1d):\n",
        "        init.normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.ConvTranspose2d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.ConvTranspose3d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.BatchNorm1d):\n",
        "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
        "        init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d):\n",
        "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
        "        init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.BatchNorm3d):\n",
        "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
        "        init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.Linear):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.LSTM):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                init.orthogonal_(param.data)\n",
        "            else:\n",
        "                init.normal_(param.data)\n",
        "    elif isinstance(m, nn.LSTMCell):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                init.orthogonal_(param.data)\n",
        "            else:\n",
        "                init.normal_(param.data)\n",
        "    elif isinstance(m, nn.GRU):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                init.orthogonal_(param.data)\n",
        "            else:\n",
        "                init.normal_(param.data)\n",
        "    elif isinstance(m, nn.GRUCell):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                init.orthogonal_(param.data)\n",
        "            else:\n",
        "                init.normal_(param.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTOqFXy3OUCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, inp , op,  hi = 512):\n",
        "        super().__init__()\n",
        "        self.inp = inp\n",
        "        self.op = op\n",
        "        self.lstm = nn.LSTM(inp, hi, 1, batch_first=True)\n",
        "        self.linear = nn.Sequential(nn.Linear(hi, op) , nn.Tanh())\n",
        "        self.apply(weight_init)\n",
        "\n",
        "    def forward(self, inpu , hi = 512):\n",
        "        h_0 = torch.zeros(1, inpu.size(0), hi)\n",
        "        c_0 = torch.zeros(1, inpu.size(0), hi)\n",
        "        outputs, (hn, cn) = self.lstm(inpu, (h_0, c_0))\n",
        "        op = hn[-1]\n",
        "        outputs = self.linear(op)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, inp , op,  hi = 512):\n",
        "        super().__init__()\n",
        "        self.inp = inp\n",
        "        self.op = op\n",
        "        self.lstm = nn.LSTM(inp, hi, 1, batch_first=True)\n",
        "        self.linear = nn.Sequential(nn.Linear(hi, op) , nn.Sigmoid())\n",
        "        self.apply(weight_init)\n",
        "\n",
        "    def forward(self, inpu , hi = 512):\n",
        "        h_0 = torch.zeros(1, inpu.size(0), hi)\n",
        "        c_0 = torch.zeros(1, inpu.size(0), hi)\n",
        "        outputs, (hn, cn) = self.lstm(inpu, (h_0, c_0))\n",
        "        op = hn[-1]\n",
        "        outputs = self.linear(op)\n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBoNG0xbnvuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_with(lr,eph,noise_size,batch,window):\n",
        "\n",
        "    nz = int(noise_size)\n",
        "    num_epochs = int(eph)\n",
        "    lr = 0.0002\n",
        "    beta1 = 0.5\n",
        "\n",
        "    window_size = int(window)\n",
        "    batch_size = int(batch)\n",
        "    real_label = 1 \n",
        "    fake_label = 0\n",
        "    feature_size = 14\n",
        "\n",
        "    criterion = nn.BCELoss()\n",
        "    netD = Discriminator(feature_size,1)\n",
        "    netG = Generator(nz,window_size*feature_size)\n",
        "\n",
        "    optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "    optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "    img_list = []\n",
        "    G_losses = []\n",
        "    D_losses = []\n",
        "    iters = 0\n",
        "    sum_err = 0\n",
        "\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        sum_err = 0 \n",
        "        for i in range(10):\n",
        "          data = MTimeSLoader(price,batch_size,window_size).get()\n",
        "          real = torch.Tensor(data)\n",
        "          # maximize log(D(x)) + log(1 - D(G(z)))\n",
        "          netD.zero_grad()\n",
        "          b_size = real.size(0)\n",
        "          label = torch.full((b_size,), real_label)\n",
        "          if not (real == real).all():\n",
        "            print(real)\n",
        "          output = netD(real)\n",
        "          errD_real = criterion(output.view(-1), label)\n",
        "          errD_real.backward()\n",
        "          D_x = output.mean().item()\n",
        "\n",
        "          noise = torch.randn(b_size, window_size, nz)\n",
        "          fake = netG(noise)\n",
        "          label.fill_(fake_label)\n",
        "          fake = fake.view(b_size,window_size,-1)\n",
        "          output = netD(fake.detach())\n",
        "          errD_fake = criterion(output.view(-1), label)\n",
        "          errD_fake.backward()\n",
        "          D_G_z1 = output.mean().item()\n",
        "          errD = errD_real + errD_fake\n",
        "          optimizerD.step()\n",
        "\n",
        "          # (2) maximize log(D(G(z)))\n",
        "          netG.zero_grad()\n",
        "          label.fill_(real_label)  \n",
        "          output = netD(fake).view(-1)\n",
        "          errG = criterion(output, label)\n",
        "          errG.backward()\n",
        "          D_G_z2 = output.mean().item()\n",
        "          optimizerG.step()\n",
        "          sum_err = sum_err + errD\n",
        "\n",
        "          if i % 50 == 0:\n",
        "              print(f'epoch : {epoch} , iter : {i} , dis err: {errD.item()}  , gen err: {errG.item()} , {D_x}, {D_G_z1}, {D_G_z2}')\n",
        "\n",
        "          G_losses.append(errG.item())\n",
        "          D_losses.append(errD.item())\n",
        "    \n",
        "  \n",
        "    print(f\"Toral error {sum_err}\")\n",
        "    # The small change: we're only going to return the accuracy\n",
        "    return sum_err"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL8vhpeUrtuX",
        "colab_type": "code",
        "outputId": "6c53d4d7-00ab-4bd1-8ad5-469b73617397",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "!pip install bayesian-optimization"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bayesian-optimization\n",
            "  Downloading https://files.pythonhosted.org/packages/72/0c/173ac467d0a53e33e41b521e4ceba74a8ac7c7873d7b857a8fbdca88302d/bayesian-optimization-1.0.1.tar.gz\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.17.4)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.3.2)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (0.21.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.14.0)\n",
            "Building wheels for collected packages: bayesian-optimization\n",
            "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.0.1-cp36-none-any.whl size=10032 sha256=8b1008a10494a8590b478eacdc609475d3856056604d3f7200f3afe62d7820cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/0d/3b/6b9d4477a34b3905f246ff4e7acf6aafd4cc9b77d473629b77\n",
            "Successfully built bayesian-optimization\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-mS9Jywa4fQ",
        "colab_type": "code",
        "outputId": "1a69fcd9-ba4a-4f21-c0f1-bc78d6e3b96e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from bayes_opt import BayesianOptimization\n",
        "\n",
        "# Bounded region of parameter space\n",
        "pbounds = {'lr': (1e-4, 1e-2),\n",
        "           'eph':(10,20),\n",
        "           'noise_size': (100,200),\n",
        "           'batch':(32,64),\n",
        "           'window':(10,20)\n",
        "           }\n",
        "\n",
        "optimizer = BayesianOptimization(\n",
        "    f=fit_with,\n",
        "    pbounds=pbounds,\n",
        "    verbose=2,\n",
        "    random_state=1,\n",
        ")\n",
        "\n",
        "optimizer.maximize(init_points=2, n_iter=2,)\n",
        "\n",
        "for i, res in enumerate(optimizer.res):\n",
        "    print(\"Iteration {}: \\n\\t{}\".format(i, res))\n",
        "\n",
        "print(optimizer.min)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|   iter    |  target   |   batch   |    eph    |    lr     | noise_... |  window   |\n",
            "-------------------------------------------------------------------------------------\n",
            "epoch : 0 , iter : 0 , dis err: 1.658155083656311  , gen err: 0.3573344349861145 , 0.7989304661750793, 0.7608800530433655, 0.6995387077331543\n",
            "epoch : 1 , iter : 0 , dis err: 0.3818158805370331  , gen err: 1.92586088180542 , 0.8308852314949036, 0.17688436806201935, 0.14575038850307465\n",
            "epoch : 2 , iter : 0 , dis err: 0.19441628456115723  , gen err: 3.46313738822937 , 0.855465292930603, 0.03623412176966667, 0.03133133053779602\n",
            "epoch : 3 , iter : 0 , dis err: 0.15336377918720245  , gen err: 4.577373504638672 , 0.8682558536529541, 0.011395626701414585, 0.01028186921030283\n",
            "epoch : 4 , iter : 0 , dis err: 0.10977791994810104  , gen err: 5.378658294677734 , 0.9010883569717407, 0.005010060500353575, 0.004614008590579033\n",
            "epoch : 5 , iter : 0 , dis err: 0.0854015052318573  , gen err: 6.066752910614014 , 0.9208036065101624, 0.00248443940654397, 0.0023186898324638605\n",
            "epoch : 6 , iter : 0 , dis err: 0.06483795493841171  , gen err: 6.566445350646973 , 0.9389417767524719, 0.0014778688782826066, 0.0014067896408960223\n",
            "epoch : 7 , iter : 0 , dis err: 0.06186094880104065  , gen err: 6.948759078979492 , 0.9412454962730408, 0.0009983957279473543, 0.0009598249453119934\n",
            "epoch : 8 , iter : 0 , dis err: 0.05086561292409897  , gen err: 7.273378372192383 , 0.9514697790145874, 0.0007179160020314157, 0.0006937644211575389\n",
            "epoch : 9 , iter : 0 , dis err: 0.04696190357208252  , gen err: 7.559319496154785 , 0.9549456238746643, 0.0005364778335206211, 0.0005212292890064418\n",
            "epoch : 10 , iter : 0 , dis err: 0.036584723740816116  , gen err: 7.802791118621826 , 0.9646562337875366, 0.00041843822691589594, 0.0004085921682417393\n",
            "epoch : 11 , iter : 0 , dis err: 0.03651103377342224  , gen err: 8.009561538696289 , 0.9646056890487671, 0.0003390689962543547, 0.00033227010862901807\n",
            "epoch : 12 , iter : 0 , dis err: 0.028267236426472664  , gen err: 8.192427635192871 , 0.9724396467208862, 0.00028177277999930084, 0.00027674128068611026\n",
            "epoch : 13 , iter : 0 , dis err: 0.02463429979979992  , gen err: 8.360445976257324 , 0.9759414792060852, 0.00023774091096129268, 0.00023393997980747372\n",
            "epoch : 14 , iter : 0 , dis err: 0.023311367258429527  , gen err: 8.511825561523438 , 0.97719407081604, 0.00020399132336024195, 0.00020107625459786505\n",
            "Toral error 0.22355800867080688\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.2236  \u001b[0m | \u001b[0m 45.34   \u001b[0m | \u001b[0m 15.8    \u001b[0m | \u001b[0m 0.000101\u001b[0m | \u001b[0m 130.2   \u001b[0m | \u001b[0m 11.47   \u001b[0m |\n",
            "epoch : 0 , iter : 0 , dis err: 1.4881426095962524  , gen err: 1.3586376905441284 , 0.34548279643058777, 0.3264998495578766, 0.25701096653938293\n",
            "epoch : 1 , iter : 0 , dis err: 0.9423091411590576  , gen err: 3.272278308868408 , 0.4127545952796936, 0.04435010626912117, 0.03791993483901024\n",
            "epoch : 2 , iter : 0 , dis err: 0.6266233921051025  , gen err: 4.590237617492676 , 0.5473394393920898, 0.011781358160078526, 0.010150442831218243\n",
            "epoch : 3 , iter : 0 , dis err: 0.4657266139984131  , gen err: 5.83840799331665 , 0.6302570104598999, 0.0032713026739656925, 0.0029134752694517374\n",
            "epoch : 4 , iter : 0 , dis err: 0.37398016452789307  , gen err: 6.7162370681762695 , 0.6901543736457825, 0.0013145280536264181, 0.001211086055263877\n",
            "epoch : 5 , iter : 0 , dis err: 0.28052347898483276  , gen err: 7.386404037475586 , 0.7579705715179443, 0.0006586662493646145, 0.0006196204922161996\n",
            "epoch : 6 , iter : 0 , dis err: 0.25299718976020813  , gen err: 7.840250492095947 , 0.7780360579490662, 0.0004116796189919114, 0.00039357037167064846\n",
            "Toral error 2.419217824935913\n",
            "| \u001b[95m 2       \u001b[0m | \u001b[95m 2.419   \u001b[0m | \u001b[95m 34.95   \u001b[0m | \u001b[95m 7.794   \u001b[0m | \u001b[95m 0.003521\u001b[0m | \u001b[95m 139.7   \u001b[0m | \u001b[95m 15.39   \u001b[0m |\n",
            "epoch : 0 , iter : 0 , dis err: 2.4926891326904297  , gen err: 0.5445119738578796 , 0.24593016505241394, 0.6527419090270996, 0.5801249146461487\n",
            "epoch : 1 , iter : 0 , dis err: 1.222777247428894  , gen err: 2.222562551498413 , 0.34193024039268494, 0.13108929991722107, 0.10833126306533813\n",
            "epoch : 2 , iter : 0 , dis err: 0.9131417870521545  , gen err: 3.954130172729492 , 0.41401374340057373, 0.022646646946668625, 0.019175361841917038\n",
            "epoch : 3 , iter : 0 , dis err: 0.7661576867103577  , gen err: 5.064022541046143 , 0.47335007786750793, 0.007048691622912884, 0.0063200839795172215\n",
            "epoch : 4 , iter : 0 , dis err: 0.5894482135772705  , gen err: 5.969799995422363 , 0.5565967559814453, 0.0027817690279334784, 0.002554752165451646\n",
            "epoch : 5 , iter : 0 , dis err: 0.4894160032272339  , gen err: 6.645893096923828 , 0.614469051361084, 0.0013781329616904259, 0.0012993483105674386\n",
            "Toral error 4.461885452270508\n",
            "| \u001b[95m 3       \u001b[0m | \u001b[95m 4.462   \u001b[0m | \u001b[95m 34.3    \u001b[0m | \u001b[95m 6.688   \u001b[0m | \u001b[95m 0.009411\u001b[0m | \u001b[95m 139.7   \u001b[0m | \u001b[95m 15.0    \u001b[0m |\n",
            "epoch : 0 , iter : 0 , dis err: 1.9668347835540771  , gen err: 0.8043732643127441 , 0.29346418380737305, 0.5176434516906738, 0.44736841320991516\n",
            "epoch : 1 , iter : 0 , dis err: 0.9626635313034058  , gen err: 2.4871621131896973 , 0.42777079343795776, 0.09945100545883179, 0.08314567059278488\n",
            "epoch : 2 , iter : 0 , dis err: 0.7844321131706238  , gen err: 4.002167701721191 , 0.46736007928848267, 0.021236924454569817, 0.01827598735690117\n",
            "epoch : 3 , iter : 0 , dis err: 0.6351523995399475  , gen err: 5.111459732055664 , 0.5337583422660828, 0.006693430710583925, 0.006027278956025839\n",
            "epoch : 4 , iter : 0 , dis err: 0.521500289440155  , gen err: 5.948314666748047 , 0.5956484079360962, 0.0028241309337317944, 0.0026102352421730757\n",
            "epoch : 5 , iter : 0 , dis err: 0.40282076597213745  , gen err: 6.672896385192871 , 0.6714310050010681, 0.0013450237456709146, 0.0012647315161302686\n",
            "epoch : 6 , iter : 0 , dis err: 0.3186136782169342  , gen err: 7.143747806549072 , 0.7278659343719482, 0.0008255576831288636, 0.0007897864561527967\n",
            "Toral error 2.913457155227661\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m 2.913   \u001b[0m | \u001b[0m 34.07   \u001b[0m | \u001b[0m 7.592   \u001b[0m | \u001b[0m 0.003464\u001b[0m | \u001b[0m 140.0   \u001b[0m | \u001b[0m 14.8    \u001b[0m |\n",
            "=====================================================================================\n",
            "Iteration 0: \n",
            "\t{'target': tensor(0.2236, grad_fn=<AddBackward0>), 'params': {'batch': 45.34470415048237, 'eph': 15.804867401632372, 'lr': 0.00010113231069171439, 'noise_size': 130.233257263184, 'window': 11.46755890817113}}\n",
            "Iteration 1: \n",
            "\t{'target': tensor(2.4192, grad_fn=<AddBackward0>), 'params': {'batch': 34.95483503260153, 'eph': 7.793903170665064, 'lr': 0.003521051197726173, 'noise_size': 139.67674742306698, 'window': 15.388167340033569}}\n",
            "Iteration 2: \n",
            "\t{'target': tensor(4.4619, grad_fn=<AddBackward0>), 'params': {'batch': 34.295783499872115, 'eph': 6.6883591661745605, 'lr': 0.009410879066055608, 'noise_size': 139.6677666673319, 'window': 15.001874152722582}}\n",
            "Iteration 3: \n",
            "\t{'target': tensor(2.9135, grad_fn=<AddBackward0>), 'params': {'batch': 34.06761657242953, 'eph': 7.5922558611769, 'lr': 0.003464265868168565, 'noise_size': 140.01654392566957, 'window': 14.797178421059982}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-4695264edbf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Iteration {}: \\n\\t{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'BayesianOptimization' object has no attribute 'min'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cyg2bNpaipS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Pass the learnt bayesian parameters into this\n",
        "\n",
        "def train(lr,eph,noise_size,batch,window):\n",
        "\n",
        "    nz = int(noise_size)\n",
        "    num_epochs = int(eph)\n",
        "    lr = 0.0002\n",
        "    beta1 = 0.5\n",
        "\n",
        "    window_size = int(window)\n",
        "    batch_size = int(batch)\n",
        "    real_label = 1 \n",
        "    fake_label = 0\n",
        "    feature_size = 1\n",
        "\n",
        "    criterion = nn.BCELoss()\n",
        "    netD = Discriminator(feature_size,1)\n",
        "    netG = Generator(nz,window_size*feature_size)\n",
        "\n",
        "    optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "    optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "    img_list = []\n",
        "    G_losses = []\n",
        "    D_losses = []\n",
        "    iters = 0\n",
        "    sum_err = 0\n",
        "\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        sum_err = 0 \n",
        "        for i in range(10):\n",
        "          data = MTimeSLoader(price,batch_size,window_size).get()\n",
        "          real = torch.Tensor(data)\n",
        "          # maximize log(D(x)) + log(1 - D(G(z)))\n",
        "          netD.zero_grad()\n",
        "          b_size = real.size(0)\n",
        "          label = torch.full((b_size,), real_label)\n",
        "          if not (real == real).all():\n",
        "            print(real)\n",
        "          output = netD(real)\n",
        "          errD_real = criterion(output.view(-1), label)\n",
        "          errD_real.backward()\n",
        "          D_x = output.mean().item()\n",
        "\n",
        "          noise = torch.randn(b_size, window_size, nz)\n",
        "          fake = netG(noise)\n",
        "          label.fill_(fake_label)\n",
        "          fake = fake.view(b_size,window_size,-1)\n",
        "          output = netD(fake.detach())\n",
        "          errD_fake = criterion(output.view(-1), label)\n",
        "          errD_fake.backward()\n",
        "          D_G_z1 = output.mean().item()\n",
        "          errD = errD_real + errD_fake\n",
        "          optimizerD.step()\n",
        "\n",
        "          # (2) maximize log(D(G(z)))\n",
        "          netG.zero_grad()\n",
        "          label.fill_(real_label)  \n",
        "          output = netD(fake).view(-1)\n",
        "          errG = criterion(output, label)\n",
        "          errG.backward()\n",
        "          D_G_z2 = output.mean().item()\n",
        "          optimizerG.step()\n",
        "          sum_err = sum_err + errD\n",
        "\n",
        "          if i % 50 == 0:\n",
        "              print(f'epoch : {epoch} , iter : {i} , dis err: {errD.item()}  , gen err: {errG.item()} , {D_x}, {D_G_z1}, {D_G_z2}')\n",
        "\n",
        "          G_losses.append(errG.item())\n",
        "          D_losses.append(errD.item())\n",
        "    \n",
        "    return netG"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mNRCoTXi6JL",
        "colab_type": "code",
        "outputId": "2bd372ad-64b7-40ff-9888-90f884501545",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "netG = train(0.0001,20,150,32,12)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch : 0 , iter : 0 , dis err: 1.8006501197814941  , gen err: 1.3055551052093506 , 0.20896044373512268, 0.2094605565071106, 0.27102208137512207\n",
            "epoch : 1 , iter : 0 , dis err: 1.3870536088943481  , gen err: 0.6999809741973877 , 0.5013543963432312, 0.5017291903495789, 0.49659475684165955\n",
            "epoch : 2 , iter : 0 , dis err: 1.3810667991638184  , gen err: 0.6980000734329224 , 0.5004507899284363, 0.49783211946487427, 0.4975794553756714\n",
            "epoch : 3 , iter : 0 , dis err: 1.395916223526001  , gen err: 0.6902440786361694 , 0.4966202974319458, 0.5014177560806274, 0.501453697681427\n",
            "epoch : 4 , iter : 0 , dis err: 1.3815889358520508  , gen err: 0.6968743205070496 , 0.5011410713195801, 0.4987855553627014, 0.4981399178504944\n",
            "epoch : 5 , iter : 0 , dis err: 1.3863903284072876  , gen err: 0.6967782378196716 , 0.49898210167884827, 0.4990280568599701, 0.49818775057792664\n",
            "epoch : 6 , iter : 0 , dis err: 1.3659768104553223  , gen err: 0.7057017087936401 , 0.5047994256019592, 0.4945886433124542, 0.49376195669174194\n",
            "epoch : 7 , iter : 0 , dis err: 1.4013195037841797  , gen err: 0.6986462473869324 , 0.4953494071960449, 0.502831757068634, 0.4972582757472992\n",
            "epoch : 8 , iter : 0 , dis err: 1.4079945087432861  , gen err: 0.6862936615943909 , 0.4948233366012573, 0.5056144595146179, 0.5034387111663818\n",
            "epoch : 9 , iter : 0 , dis err: 1.3764934539794922  , gen err: 0.6937074661254883 , 0.4975612163543701, 0.49260056018829346, 0.4997199475765228\n",
            "epoch : 10 , iter : 0 , dis err: 1.4026858806610107  , gen err: 0.6849527359008789 , 0.5087122917175293, 0.5165526270866394, 0.5041140913963318\n",
            "epoch : 11 , iter : 0 , dis err: 1.3754940032958984  , gen err: 0.7025529146194458 , 0.5016108751296997, 0.4961935877799988, 0.4953191876411438\n",
            "epoch : 12 , iter : 0 , dis err: 1.3499293327331543  , gen err: 0.7384501099586487 , 0.5108913779258728, 0.49253660440444946, 0.4778541922569275\n",
            "epoch : 13 , iter : 0 , dis err: 1.3661032915115356  , gen err: 0.7849288582801819 , 0.5844745635986328, 0.5635405778884888, 0.45615267753601074\n",
            "epoch : 14 , iter : 0 , dis err: 1.4412778615951538  , gen err: 0.6717405915260315 , 0.48622211813926697, 0.5133389830589294, 0.5108187198638916\n",
            "epoch : 15 , iter : 0 , dis err: 1.3861117362976074  , gen err: 0.6976580023765564 , 0.49830108880996704, 0.49820366501808167, 0.4977496266365051\n",
            "epoch : 16 , iter : 0 , dis err: 1.360818862915039  , gen err: 0.6374802589416504 , 0.48343992233276367, 0.46952903270721436, 0.5286228656768799\n",
            "epoch : 17 , iter : 0 , dis err: 1.3550055027008057  , gen err: 0.7427564859390259 , 0.4831554889678955, 0.46612122654914856, 0.47580140829086304\n",
            "epoch : 18 , iter : 0 , dis err: 1.4102530479431152  , gen err: 0.6931949257850647 , 0.502875804901123, 0.5146183967590332, 0.49998578429222107\n",
            "epoch : 19 , iter : 0 , dis err: 1.38627028465271  , gen err: 0.7104876637458801 , 0.4975910186767578, 0.4975670576095581, 0.4914044737815857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD98Mf0LmuLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent = torch.randn(10000, 12, 150)\n",
        "dat = netG(latent)\n",
        "dat = dat.view(10000,12,-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg_ocgQGnREK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rets = []\n",
        "for i in range(10000):\n",
        "  rets.append(dat[i][-1][0].item())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LimA3jMp4ZkR",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}